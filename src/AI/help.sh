#!/bin/bash

echo "üöÄ OASIS AI SERVICE - GPU OPTIMIZED"
echo "======================================"
echo ""
echo "Available npm scripts:"
echo ""

echo "üìã CORE SERVICES:"
echo "  npm start                    - Start AI service (default config)"
echo "  npm run start:gpu            - Start with GPU optimization (GPU XXL)"
echo "  npm run start:cpu            - Force CPU-only mode"
echo "  npm run start:gpu-max        - Maximum GPU performance (min VRAM padding)"
echo "  npm run start:gpu-conservative - Conservative GPU (more VRAM padding)"
echo "  npm run start:auto           - Auto-detect optimal GPU configuration"
echo "  npm run build               - Build the service"
echo "  npm run setup               - Run installation setup"
echo ""

echo "üîç GPU DIAGNOSTICS:"
echo "  npm run gpu:check      - Check GPU status and recommendations"
echo "  npm run diagnostic     - Same as gpu:check (alias)"
echo "  npm run verify-gpu     - Full GPU verification (check + test)"
echo ""

echo "‚ö° GPU PERFORMANCE TESTS:"
echo "  npm run gpu:test-simple          - Simple GPU performance test"
echo "  npm run gpu:test-real            - Real model test with VRAM monitoring"
echo "  npm run test:local-model         - Test local model loading (alias)"
echo ""

echo "üîß FUNCTION CALLING TESTS:"
echo "  npm run gpu:test-functions       - Test functions with custom wrapper"
echo "  npm run gpu:test-simple-functions - Test functions without wrapper (recommended)"
echo "  npm run test:functions           - Simple function tests (alias)"
echo ""

echo "üß™ LEGACY TESTS:"
echo "  npm run llama:test-handler       - Test llama handler"
echo "  npm run llama:test-functions     - Test llama functions"
echo "  npm run llama:test-no-functions  - Test without functions"
echo ""

echo "üèÜ COMPREHENSIVE TESTING:"
echo "  npm run test:all-gpu   - Run all GPU tests (check + simple + functions)"
echo "  npm run benchmark      - Performance benchmark (simple + functions)"
echo ""

echo "üí° QUICK START COMMANDS:"
echo "  1. npm run gpu:check            # Check your GPU setup"
echo "  2. npm run start:auto           # Auto-start with optimal GPU config"
echo "  3. npm run start:gpu            # Manual GPU start (GPU XXL optimized)"
echo "  4. npm run test:all-gpu         # Comprehensive test"
echo ""

echo "üìä EXPECTED PERFORMANCE (GPU):"
echo "  ‚Ä¢ Model Loading: ~5-6GB VRAM usage"
echo "  ‚Ä¢ Inference Speed: 200-500ms per response"  
echo "  ‚Ä¢ GPU Utilization: 100% (fully optimized)"
echo ""

echo "üîó For detailed information, see README.md"