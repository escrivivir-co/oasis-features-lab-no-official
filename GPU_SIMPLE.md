# ðŸš€ OASIS GPU - ConfiguraciÃ³n Simplificada

## ðŸ’¡ **La Realidad: node-llama-cpp es MUY inteligente**

`node-llama-cpp` v3.13.0 maneja automÃ¡ticamente:
- âœ… DetecciÃ³n de GPU NVIDIA
- âœ… CompilaciÃ³n con CUDA si estÃ¡ disponible  
- âœ… Fallback automÃ¡tico a CPU
- âœ… OptimizaciÃ³n de capas GPU/CPU
- âœ… GestiÃ³n de memoria VRAM

## ðŸŽ¯ **Lo ÃšNICO que necesitas configurar:**

### **1. Acceso GPU en Docker (YA HECHO):**
```yaml
# docker-compose.yml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: all
          capabilities: [gpu]
```

### **2. Variables de entorno (YA CONFIGURADAS):**
```bash
GPU_ENABLED=true      # node-llama-cpp decide automÃ¡ticamente
GPU_LAYERS=auto       # node-llama-cpp optimiza automÃ¡ticamente  
VRAM_PADDING=256      # Reserva VRAM para estabilidad
```

### **3. Dependencias de compilaciÃ³n (YA AÃ‘ADIDAS):**
```dockerfile
# Dockerfile - Solo para que node-llama-cpp pueda compilar
RUN apt-get install -y git cmake build-essential
```

## ðŸš€ **Uso sÃºper simple:**

```bash
# Iniciar OASIS (GPU automÃ¡tica si disponible)
npm run up

# Verificar que AI funciona
npm run ai:health
npm run ai:test

# Ver logs del AI service
npm run ai:logs
```

## ðŸŽ‰ **Â¡Eso es todo!**

- Si tienes GPU NVIDIA + drivers â†’ node-llama-cpp la usa automÃ¡ticamente
- Si no tienes GPU compatible â†’ node-llama-cpp usa CPU automÃ¡ticamente  
- Si hay problemas â†’ logs muestran el fallback y razÃ³n

**No necesitas gestionar nada manualmente.** ðŸ¤–âœ¨